Strongly Connected = 모든 node의 pair가 mutually connected(서로 연결되는 양방향 path가 있음)

SCC 덩어리 찾을 때 어케했더라?
1. DFS on G, checking finish time
2. DFS on G^T
3. f1 > f2 > ...

**Directed Acyclic Graph: DAG**
![](https://i.imgur.com/jO2RcJg.png)
왼덩이 우덩이로 나눌 수 있는데, 덩어리 관점에서 사이클이 없음.

indegree: 들어오는 간선
outdegree: 나가는 간선

#### DAG
> DAG is a directed graph that contains no directed cycles.
#### Topological Order
>A topological order of a directed graph G = (V, E) is an ordering of its nodes as v1,v2,...,vn so that **for every edge (vi, vj) we have i < j.**

**이제 우리는 Graph가 DAG라는 것과 Graph가 Topological Order를 갖는다는게 동치임을 보일 것이다.**
먼저 Topological Order를 가지면 DAG라는 것은 귀류법을 통해 쉽게 증명 가능하다.
DAG가 Topological Order를 갖는다는 것은 두 단계로 나누어 보겠다.
<u>Lemma 1</u>
_if G is a DAG, then G has a node with no incoming edges._
귀류법으로 증명 가능하다.
즉 모든 노드가 적어도 하나 이상의 incoming edge를 갖는다고 해보자. 그렇다면 각 노드에서 backward하게 다른 노드로 계속 갈 수 있고, 그래프의 노드의 갯수는 유한하므로 언젠가 특정 노드를 두 번 방문하는 시점이 오게 된다. 특정 노드를 두 번 방문한다는 것은 cycle이 존재한다는 의미이므로 모순. Q.E.D.
<u><b>Lemma 2</b></u>
_If G is a DAG, then G has a Topological ordering._
이제 DAG로부터 G를 수학적 귀납법으로 generate해보자.
Lemma 1에서 어떤 DAG에 대하여 indegree = 0인 노드가 존재한다. G에서 그 노드를 제거해도 여전히 DAG인 것은 자명하므로, 그 노드를 제거하자. 그리고 그 노드를 Topological Ordering의 맨 뒤에 추가하자. 그렇다면 indegree가 0인 노드들만(**즉 outgoing edge만 가지는 노드들만**) 삽입이 되므로 당연히 Topological Ordering의 조건을 만족한다.
위와 같은 알고리즘은 O(V + E) 시간으로 정렬이 가능하다.

**Topological Ordering**
노드를 일차원 수직선에 깐다.
순서대로 깔아서 화살표가 **오른쪽으로만 가게** 하면됨.
요고는 DAG에서만 논할 수 있음.
이것저것 순열을 만들어서 해보면 유일하지 않다는 것을 쉽게 알 수 있음.
just 왼쪽에서 오른쪽으로 가게 하면됨.

indegree = 0 인 노드가 있다고 해서 DAG인건 아니다.
pf by counter example.
![](https://i.imgur.com/n1BzQN2.png)


```
TOPOLOGICAL_SORT
	call DFS to compute finish times v.f for each vertex v
	as each vertex is finished, insert it onto the front of a linked list
return linked list
```

앞에서 indegree = 0인 노드를 제거 하는 것이 앞에서 부터 generation 하는 방법이라면 **이 방법은 제일 끝에서부터 역으로 generation하는 방법이다!**

어떤 G에서 Topological ordering을 뽑아내고 싶다...
1. Check whether the graph is DAG / By DFS, BFS. // 노드에서 뿜어져 나오는 간선이 모두 마킹된것만 가리키면 싸이클

T.O를 뽑는 과정 및 시간 복잡도:
1. indegree = 0 인 노드를 marking함.
2. 걔를 빼고, 그래프를 수정함. 즉 뺀 놈이랑 연결된 노드의 indegree를 1씩 낮춤.
3. iterate till the graph be a empty graph.
노드를 뽑고(n) 간선을 제거(m) => O(n + m)

# Heapsort and Priority Queue
## 6.1 Heap
Sort는 nlogn이 젤 빠르다.

근데 Sort된 배열에 insert하는 경우?
업다운식으로 반반 나눠서 하면 O(log n)의 시간이 소요될 것. 
그리고 뒤에 아들이 밀리니까 O(n)일 거임. 
delete도 마찬가지.
Find(min, med, max) = O(1)
위의 상황은 list다.

**근데 med, max가 필요없는 상황이면 find min을 logn으로 만들고 insert, delete도 logn으로 최적화 할 수 있다.**
**그 구현을 priority queue로 한다. heap구조로**

> The (binary) heap data structure is an array object that we can view as a nearly complete binary tree.

![](https://i.imgur.com/XKqxEnm.png)


왼쪽이 max-heap, 오른쪽은 실제 메모리 상태(array)를 나타낸다.
보면 알겠지만 너비 우선적으로 채운다.
leaf node는 tree에서 자식이 없는 노드.
**Max-heap property: A\[parent(i)] >= A\[i].**
**즉 부모는 자식보다 작지 않다고, 위 가정에 의하면 root node가 heap의 maximum이다.**
min-heap는 반대로 부모가 자식보다 크지 않다.

## 6.2 Maintaining the Heap property

>[!question] How to Maintain the heap property?
> *MAX-HEAPIFY* 함수를 이용해서 max-heap property를 maintain한다.

```pseudocode
MAX-HEAPIFY(A, i)
	l = LEFT(i)
	r = RIGHT(i)
	if l <= A.heapsize and A[l] > A[i]
		largest = l
	else largest = i
	if r <= A.heapsize and A[r] > A[i]
		largest = r
	if largest is NOT i
		exchange A[i] with A[largest]
		MAX-HEAPIFY(A, largest)
```

![](https://i.imgur.com/hG4P1m3.png)

`MAX-HEAPIFY` 를 수행하면 i번째 노드를 루트 노드로 갖는 subtree는 max-heap이 된다.
직관적으로 `MAX-HEAPIFY` 는 최대가 heap의 높이 만큼 탐색해야 하므로 O(log n)이 된다.
## 6.3 Building a heap
`MAX_HEAPIFY` 를 bottom-up으로 사용하면 array를 max-heap으로 만들 수 있다.

```
BUILD-MAX-HEAP(A)
	A.heapsize = A.length
	for i = floor(A.length / 2) downto 1
		MAX-HEAPIFY(A, i) 
```

leaf 노드는 max-heap-property를 만족한다. leaf 노드는 max-heapify 할 필요가 없다.
만약 만족 안하면 부모랑 자식 위치를 바꿔버리면서 밑으로 쭉쭉 내려가면서 다시 해야함.

리프 노드를 제외한 모든 노드에 대해 하는데 각 노드에서 최악의 경우 가장 바닥까지 내려가야 함.
![](https://i.imgur.com/ydx8QXu.png)



이제 heap 만드는데 필요한 시간 복잡도를 계산해보자.
각 노드마다 뒤집는 최악의 경우의 수는 depth = log n 이다.
O(nlogn)이 찐찐 최악.

근데 좀 더 tight한 분석을 해보자. 
리프는 뒤집기 필요없고
리프위는 한 번
리프 위 위는 두번 ...
**이런식으로 분석을 하면 Build_Heap에는 O(n) 시간이 걸린다.**

## 6.5 Heap Implementation of Priority Queue

1. INSERT: Heap에 insert할 때 맨 끝에 집어넣음. Increase key(or decrease key)를 수행하며 제 자리를 찾게 만든다. O(log n).
2. Extract-Max: 최댓값을 제거. 
   마지막 끄트머리에 있는 노드와 루트 노드의 위치를 바꾼 뒤 루트에 대해 heapify를 수행하면 됨. 
   Heapify의 시간 복잡도인 O(log n).
3. Increase-key(Decrease-key): key value를 증가시킴. 부모(자식)와 비교하여 작으면 가만히 두고 크면 바꾼뒤 다시 부모와 비교한다. O(log n).
4. GET MAXIMUM: Maximum은 Root에 접근하면 되므로 O(1).

**어? 다 O(logn)이네? 미친 구조.**

## 6.4 Heapsort
이제 Heapsort를 해보자.
BuildHeap(linear time)을 하고
대가리를 빼서 맨 뒤에 박은 다음 새롭게 heap을 만듬(log time)
남은게 없을 때 까지~
=> O(nlogn)

장점
**Sorts in place: 추가적인 메모리를 사용하지 않음**
mergesort는 추가적인 메모리를 사용함

다음 시간에 Shortest path를 찾는 알고리즘을 해볼 것임.
