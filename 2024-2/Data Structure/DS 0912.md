짧은 퀴즈가 있을 예정
하나의 주제에 대한 sub-question들로 구성

**Landau symbol** to represent asymptotic analysis. 랜다 기호
어떤 알고리즘이 더 좋은지 결정하기 위해 우리는 Algorithm analysis를 한다.
그 방법이 asymptotic anal.

![[Pasted image 20240912112217.png]]
위의 선은 Maximum case, 밑의 선은 average case.
n이 엄청 작으면 Linear가 오히려 유리한데 n이 커지면 binary가 유리하다.
**이것이 우리가 Asymptotic Analysis를 배우는 이유!**

![[Pasted image 20240912112645.png]]
![[Pasted image 20240912112655.png]]
이게 Asymptotic Analysis의 관점. n이 커질 때 leading term만 본다.
![[Pasted image 20240912113229.png]]
색깔이 바뀐듯 함. overhead는 퀵소트가 더 크다고 하는 걸 볼 때, 오버헤드라는 것은 반복되는 연산의 크기인 듯 하다.
> 알고리즘에서 **overhead**는 특정 작업을 수행하는 데 있어서 추가적으로 발생하는 비용이나 리소스를 말합니다. 이는 메모리, 시간, 계산 복잡도 또는 네트워크 자원 등 여러 형태로 나타날 수 있습니다. 일반적으로 알고리즘의 핵심 작업과 직접 관련이 없는, 하지만 그 작업을 수행하기 위해 필요한 부수적인 과정들이 **overhead**에 해당합니다.

우리의 함수는 시간/메모리 요구값을 의미하는 거라고 가정하고 시작하자. 
그리고 n>=0, 단조증가하는 정의역이 양수인 함수라고 가정.

O는 weak upper bound, o는 tight upper bound.

![[Pasted image 20240912114916.png]]
\=<는 = + < 와 같음

![[Pasted image 20240912115001.png]]
역함수 관계


---
![[Pasted image 20240912115115.png]]
1. symmetry
2. reflexivity
3. transitivity
1은 직관적으로 자명
2도 자명
3도 자명,, 약간 수학에서의 군 같은 느낌.
![[Pasted image 20240912115508.png]]
이름이 있다. 백준 풀다보면 보이죠?
logarithmic에서 밑은 뭐가 와도 ln이랑 같다고 생각한다. 밑변환공식

**그러나 exponential에서는 밑을 무시하지 않는다.**
exponential에서는 밑의 크기에 따라 asymptotic behavior가 다르기 때문에..
![[Pasted image 20240912115949.png]]
### Weak Ordering
어려운걸 weak한 쉬운거로 대체
![[Pasted image 20240912120027.png]]
그럼 내 질문: (log n)^ m은 항상 n 보다 작나? 이거 해결 가능.
![[Pasted image 20240912120316.png]]
q만 있는게 더 쉽잖아!
![[Pasted image 20240912120354.png]]
![[Pasted image 20240912120554.png]]
NP 문제인지 아닌지 물어보는 경우도 있음.

요약: 랜다 기호 봤고, 왜 배우는지 배웠음.
다음엔 코드 볼거임.
![[스크린샷 2024-09-12 오후 2.09.00.png]]
